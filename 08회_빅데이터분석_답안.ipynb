{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5609cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
       "div.text_cell_render.rendered_html{font-size:20pt;}\n",
       "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:24pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:24pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
       "table.dataframe{font-size:24px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:24pt;}\n",
    "div.text_cell_render.rendered_html{font-size:20pt;}\n",
    "div.text_cell_render li, div.text_cell_render p, code{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:24pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:24pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:24pt;padding:5px;}\n",
    "table.dataframe{font-size:24px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6a5b8",
   "metadata": {},
   "source": [
    "# 01. 빅데이터 특징과 세부내용에 대한 설명으로 알맞지 않은 것은?\n",
    "① Veracity - 데이터의 가치를 반영한다. \n",
    "\n",
    "② Volume - 데이터의 양이 크다. \n",
    "\n",
    "③ Velocity - 데이터가 실시간으로 변한다. \n",
    "\n",
    "④ Variety - 데이터가 다양하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201608b",
   "metadata": {},
   "source": [
    "## 답: ①\n",
    "\n",
    "## 설명:\n",
    "빅데이터의 특징은 3V 또는 5V로 설명돼. \n",
    "\n",
    "**3V (기본 특징):**\n",
    "- **Volume (규모)**: 데이터의 양이 매우 크다\n",
    "- **Velocity (속도)**: 데이터가 실시간으로 빠르게 생성되고 변한다\n",
    "- **Variety (다양성)**: 정형, 반정형, 비정형 등 다양한 형태의 데이터\n",
    "\n",
    "**확장된 5V (추가 특징):**\n",
    "- **Veracity (진실성)**: 데이터의 정확성과 신뢰성 - ①번에서 '가치'라고 한 건 틀렸어\n",
    "- **Value (가치)**: 데이터로부터 추출할 수 있는 실제 가치\n",
    "\n",
    "① 번이 틀린 이유는 Veracity는 데이터의 '진실성/정확성'을 의미하는데, 문제에서는 '가치'라고 설명했기 때문이야. 데이터의 '가치'는 Value에 해당하는 개념이지."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47cdf2",
   "metadata": {},
   "source": [
    "# 02. 데이터 수집, 전처리, 분석 작업을 모두 지원하는 것은?\n",
    "① 데이터베이스 \n",
    "\n",
    "② 빅데이터 플랫폼 \n",
    "\n",
    "③ 데이터 시각화 툴 \n",
    "\n",
    "④ 빅데이터 가치사슬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0baeb05",
   "metadata": {},
   "source": [
    "## 답: ②\n",
    "\n",
    "## 설명:\n",
    "**빅데이터 플랫폼**은 데이터 처리의 전체 과정을 통합적으로 지원하는 시스템이야.\n",
    "\n",
    "**빅데이터 플랫폼의 주요 기능:**\n",
    "- **데이터 수집**: 다양한 소스에서 데이터 수집 (크롤링, API 연동, 센서 데이터 등)\n",
    "- **데이터 저장**: 대용량 데이터 분산 저장 (HDFS, NoSQL 등)\n",
    "- **데이터 전처리**: 정제, 변환, 통합 작업\n",
    "- **데이터 분석**: 배치 처리, 실시간 분석, 머신러닝 등\n",
    "- **데이터 시각화**: 분석 결과 시각화\n",
    "\n",
    "**다른 선택지가 틀린 이유:**\n",
    "- ① 데이터베이스: 주로 저장과 조회 기능에 특화됨\n",
    "- ③ 데이터 시각화 툴: 시각화에만 집중, 수집/전처리는 못함\n",
    "- ④ 빅데이터 가치사슬: 개념적인 프로세스 모델이지 실제 도구가 아님\n",
    "\n",
    "예를 들어 Hadoop, Spark 같은 게 대표적인 빅데이터 플랫폼이야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255972e",
   "metadata": {},
   "source": [
    "# 03. 다음 중 개인정보에 대한 설명으로 적절하지 않은 것은?\n",
    "① 개인정보처리자는 통계작성, 과학적 연구, 공익적 기록보존 등을 위하여 정보주체의 동의 없이 가명정보를 처리할 수 있다. \n",
    "\n",
    "② 개인정보의 익명 처리를 위해서는 정보주체의 동의가 필요하다. \n",
    "\n",
    "③ 개인정보의 처리와 보호에 관한 사안을 독립적으로 수행하기 위해 개인정보보호위원회를 설립했다. \n",
    "\n",
    "④ 활용되는 정보로는 처리 수준에 따라 개인정보, 가명정보, 익명정보로 분류할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd96e04",
   "metadata": {},
   "source": [
    "## 답: ②\n",
    "\n",
    "## 설명:\n",
    "②번이 틀린 이유는 **익명정보는 개인정보가 아니기 때문**이야. \n",
    "\n",
    "**개인정보 처리 수준별 분류:**\n",
    "\n",
    "1. **개인정보**\n",
    "   - 특정 개인을 식별할 수 있는 정보\n",
    "   - 처리하려면 정보주체의 동의 필요\n",
    "\n",
    "2. **가명정보**\n",
    "   - 개인정보를 가명처리한 정보\n",
    "   - 추가 정보 없이는 특정 개인을 알아볼 수 없게 처리\n",
    "   - 통계, 과학적 연구, 공익적 기록보존 등의 목적으로 **동의 없이 처리 가능** (①번 맞음)\n",
    "\n",
    "3. **익명정보**\n",
    "   - 더 이상 개인을 식별할 수 없도록 완전히 처리한 정보\n",
    "   - **개인정보보호법의 적용을 받지 않음**\n",
    "   - 따라서 **정보주체의 동의가 필요 없음** (②번 틀림)\n",
    "\n",
    "익명처리가 완료되면 그건 더 이상 개인정보가 아니기 때문에 개인정보보호법의 규제를 받지 않고 자유롭게 활용할 수 있어."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd5286",
   "metadata": {},
   "source": [
    "# 04. 하향식 접근방법에 대한 설명 중 옳지 않은 것은?\n",
    "① 문제 탐색 단계에서는 단순하게 나열한다. \n",
    "\n",
    "② 문제 정의는 상위 목표를 구체화하고 하위 목표로 세분화하여 문제의 범위와 목표를 명확히 한다. \n",
    "\n",
    "③ 해결방안 탐색은 문제에 대한 이해를 바탕으로 가능한 해결책을 찾는 과정이다. \n",
    "\n",
    "④ 타당성 검토는 도출된 해결책이 현실적이고 실행 가능한지를 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faec764",
   "metadata": {},
   "source": [
    "## 답: ①\n",
    "\n",
    "## 설명:\n",
    "**하향식(Top-Down) 접근방법**은 큰 문제를 작은 단위로 분해해 나가는 체계적인 방법이야.\n",
    "\n",
    "**하향식 접근방법의 단계:**\n",
    "\n",
    "1. **문제 탐색**\n",
    "   - 문제를 **체계적으로 분석하고 구조화**하는 단계\n",
    "   - '단순하게 나열'하는 게 아니라 **논리적으로 분해하고 구조화**함 (①번 틀림)\n",
    "   - 문제 간의 관계와 우선순위를 파악\n",
    "\n",
    "2. **문제 정의** (②번 맞음)\n",
    "   - 상위 목표를 명확히 하고\n",
    "   - 하위 목표로 세분화\n",
    "   - 문제의 범위와 목표를 구체화\n",
    "\n",
    "3. **해결방안 탐색** (③번 맞음)\n",
    "   - 정의된 문제에 대한 해결 방법 모색\n",
    "   - 다양한 대안 검토\n",
    "\n",
    "4. **타당성 검토** (④번 맞음)\n",
    "   - 해결책의 실현 가능성 평가\n",
    "   - 비용, 시간, 자원 등 고려\n",
    "\n",
    "하향식 접근은 '큰 그림 → 세부사항'으로 진행되며, 단순 나열이 아니라 **체계적 분해와 구조화**가 핵심이야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d8ae1",
   "metadata": {},
   "source": [
    "# 05. 빅데이터 분석 방법론의 데이터 분석 단계에서 수행하는 태스크로 옳지 않은 것은?\n",
    "① 데이터 확인 및 추출 \n",
    "\n",
    "② 데이터 모델링 \n",
    "\n",
    "③ 모델링 적용 및 운영방안 \n",
    "\n",
    "④ 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c13f4",
   "metadata": {},
   "source": [
    "## 답: ③\n",
    "\n",
    "## 설명:\n",
    "빅데이터 분석 방법론의 주요 단계를 구분해보면:\n",
    "\n",
    "**1. 분석 기획 단계**\n",
    "- 분석 목표 설정\n",
    "- 프로젝트 계획 수립\n",
    "\n",
    "**2. 데이터 준비 단계**\n",
    "- 데이터 수집\n",
    "- 데이터 저장\n",
    "\n",
    "**3. 데이터 분석 단계** ← 이 문제가 물어보는 단계\n",
    "- ① **데이터 확인 및 추출**: 필요한 데이터 확인하고 추출\n",
    "- ④ **데이터 준비**: 전처리, 정제, 변환 작업\n",
    "- ② **데이터 모델링**: 통계분석, 머신러닝 모델 구축\n",
    "\n",
    "**4. 시스템 구현 단계**\n",
    "- ③ **모델링 적용 및 운영방안**: 실제 시스템에 적용 ← 이건 '시스템 구현' 단계임\n",
    "- 시스템 설계 및 구축\n",
    "\n",
    "**5. 평가 및 전개 단계**\n",
    "- 모델 평가\n",
    "- 결과 활용 및 개선\n",
    "\n",
    "③번 '모델링 적용 및 운영방안'은 데이터 분석이 끝난 후 **시스템 구현 단계**에서 하는 일이야. 분석 단계에서는 모델을 만들기까지만 하고, 실제 적용은 다음 단계에서 해."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7db2c",
   "metadata": {},
   "source": [
    "# 06. 다음 중 유의미한 변수를 고르는 작업을 수행하는 단계로 알맞은 것은?\n",
    "① 데이터 탐색 \n",
    "\n",
    "② 데이터 모델링 \n",
    "\n",
    "③ 데이터 전처리 \n",
    "\n",
    "④ 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf4a0d",
   "metadata": {},
   "source": [
    "## 답: ①\n",
    "\n",
    "## 설명:\n",
    "**유의미한 변수를 고르는 작업**은 **변수 선택(Feature Selection)** 또는 **특성 선택**이라고 하는데, 이건 **데이터 탐색** 단계에서 주로 수행돼.\n",
    "\n",
    "**각 단계별 역할:**\n",
    "\n",
    "**① 데이터 탐색 (EDA: Exploratory Data Analysis)**\n",
    "- 데이터의 특성과 패턴 파악\n",
    "- 변수 간 상관관계 분석\n",
    "- **유의미한 변수 식별 및 선택** ← 정답!\n",
    "- 이상치 탐지\n",
    "- 기술 통계량 확인\n",
    "\n",
    "**② 데이터 모델링**\n",
    "- 선택된 변수를 사용해 모델 구축\n",
    "- 알고리즘 선택 및 학습\n",
    "\n",
    "**③ 데이터 전처리**\n",
    "- 결측치 처리\n",
    "- 이상치 처리\n",
    "- 데이터 변환 (정규화, 표준화 등)\n",
    "\n",
    "**④ 데이터 시각화**\n",
    "- 데이터나 분석 결과를 그래프로 표현\n",
    "- 탐색 단계의 보조 도구로 사용됨\n",
    "\n",
    "데이터 탐색 단계에서 상관분석, 분산 분석 등을 통해 목표 변수와 관련성이 높은 변수들을 찾아내고, 중요도가 낮거나 중복되는 변수는 제거하는 작업을 해."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb93709",
   "metadata": {},
   "source": [
    "# 07. 다음 중 분석 유형을 구분할 때 데이터 분석 방법은 충분히 이해하고 있지만 조직 내 분석 대상을 인지하지 못하는 유형은?\n",
    "① 최적화(Optimization) \n",
    "\n",
    "② 발견(Discovery) \n",
    "\n",
    "③ 통찰(Insight) \n",
    "\n",
    "④ 솔루션(Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73329692",
   "metadata": {},
   "source": [
    "## 답: ④\n",
    "\n",
    "## 설명:\n",
    "이 문제는 **분석 업무의 4가지 유형**을 다루고 있어. 2x2 매트릭스로 구분하는데:\n",
    "- X축: 분석 대상의 명확성 (무엇을 분석할지 아는가?)\n",
    "- Y축: 분석 방법의 명확성 (어떻게 분석할지 아는가?)\n",
    "\n",
    "**4가지 분석 유형:**\n",
    "\n",
    "**① 최적화(Optimization)**\n",
    "- 분석 대상 명확 ○ / 분석 방법 명확 ○\n",
    "- 무엇을 어떻게 할지 모두 알고 있음\n",
    "- 예: 기존 프로세스 개선, 효율화\n",
    "\n",
    "**② 발견(Discovery)**\n",
    "- 분석 대상 불명확 × / 분석 방법 불명확 ×\n",
    "- 무엇을 어떻게 할지 모두 모름\n",
    "- 예: 탐색적 분석, 새로운 기회 발굴\n",
    "\n",
    "**③ 통찰(Insight)**\n",
    "- 분석 대상 명확 ○ / 분석 방법 불명확 ×\n",
    "- 무엇을 분석할지는 알지만 방법을 모름\n",
    "- 예: 고객 이탈 원인은 찾고 싶은데 어떻게 분석할지 모름\n",
    "\n",
    "**④ 솔루션(Solution)** ← 정답!\n",
    "- 분석 대상 불명확 × / 분석 방법 명확 ○\n",
    "- **분석 방법(기술)은 알지만 무엇을 분석할지 모름**\n",
    "- 예: 머신러닝 기술은 있는데 어디에 적용할지 모름\n",
    "\n",
    "문제에서 \"데이터 분석 방법은 충분히 이해하고 있지만(방법 ○) 조직 내 분석 대상을 인지하지 못하는(대상 ×)\" 유형은 바로 **솔루션(Solution)** 유형이야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c98ac",
   "metadata": {},
   "source": [
    "# 08. 외부 및 내부 데이터에 대한 설명으로 옳지 않은 것은?\n",
    "① 내부 데이터는 내부 조직 간 협의에 의해 사용 가능하다. \n",
    "\n",
    "② 내부 데이터는 조직 내부에서 생성되거나 보유하는 데이터를 의미한다. \n",
    "\n",
    "③ 외부 데이터는 외부 출처에서 수집한 데이터를 의미하며, 보통 공개된 데이터이거나 외부 제공 업체 등을 통해 확보한다. \n",
    "\n",
    "④ 외부 데이터는 어떤 단계에서나 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317844f",
   "metadata": {},
   "source": [
    "## 답: ④\n",
    "\n",
    "## 설명:\n",
    "\n",
    "**내부 데이터 (①, ②번 맞음)**\n",
    "- 조직 내부에서 생성/보유하는 데이터\n",
    "- 예: 고객 데이터, 거래 내역, 재무 데이터, 인사 데이터 등\n",
    "- 내부 조직 간 협의로 사용 가능\n",
    "- 접근성이 좋고 신뢰도가 높음\n",
    "\n",
    "**외부 데이터 (③번 맞음)**\n",
    "- 조직 외부에서 수집한 데이터\n",
    "- 예: 공공 데이터, 시장 조사 데이터, SNS 데이터, 경쟁사 정보 등\n",
    "- 공개 데이터 또는 외부 업체를 통해 확보\n",
    "\n",
    "**④번이 틀린 이유:**\n",
    "외부 데이터는 **사용 목적과 법적 제약, 데이터 품질 등을 고려해야** 해서 \"어떤 단계에서나\" 자유롭게 사용할 수 있는 건 아니야.\n",
    "\n",
    "**외부 데이터 사용 시 고려사항:**\n",
    "- **법적 제약**: 저작권, 개인정보보호법, 라이선스 확인 필요\n",
    "- **데이터 품질**: 정확성, 신뢰성 검증 필요\n",
    "- **적합성**: 분석 목적에 맞는지 검토 필요\n",
    "- **비용**: 유료 데이터의 경우 예산 고려\n",
    "- **시의성**: 데이터가 최신인지 확인\n",
    "\n",
    "특히 분석 초기 단계에서 외부 데이터를 무분별하게 사용하면 법적 문제나 품질 문제가 발생할 수 있어서, 적절한 검토 과정을 거쳐야 해."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0ce1a",
   "metadata": {},
   "source": [
    "# 09. 다음 중 빅데이터 분석 절차로 알맞은 것은?\n",
    "① 분석 기획 - 데이터 분석 - 데이터 준비 - 시스템 구현 - 평가 및 전개 \n",
    "\n",
    "② 데이터 준비 - 분석 기획 - 데이터 분석 - 평가 및 전개 - 시스템 구현 \n",
    "\n",
    "③ 분석 기획 - 데이터 준비 - 데이터 분석 - 시스템 구현 - 평가 및 전개 \n",
    "\n",
    "④ 데이터 준비 - 분석 기획 - 데이터 분석 - 평가 및 전개 - 시스템 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc72c66",
   "metadata": {},
   "source": [
    "## 답: ③\n",
    "\n",
    "## 설명:\n",
    "빅데이터 분석의 올바른 절차는:\n",
    "\n",
    "**1. 분석 기획 (Planning)**\n",
    "- 분석 목표 설정\n",
    "- 문제 정의\n",
    "- 분석 범위 결정\n",
    "- 프로젝트 계획 수립\n",
    "- ⇒ \"무엇을 왜 분석할 것인가?\" 먼저 정해야 함\n",
    "\n",
    "**2. 데이터 준비 (Data Preparation)**\n",
    "- 데이터 수집\n",
    "- 데이터 저장\n",
    "- 데이터 전처리 (정제, 변환)\n",
    "- ⇒ 기획한 내용에 맞춰 데이터를 준비\n",
    "\n",
    "**3. 데이터 분석 (Data Analysis)**\n",
    "- 데이터 탐색 (EDA)\n",
    "- 변수 선택\n",
    "- 모델링\n",
    "- ⇒ 준비된 데이터로 실제 분석 수행\n",
    "\n",
    "**4. 시스템 구현 (Implementation)**\n",
    "- 분석 모델을 실제 시스템에 적용\n",
    "- 운영 환경 구축\n",
    "- ⇒ 분석 결과를 실무에 적용\n",
    "\n",
    "**5. 평가 및 전개 (Evaluation & Deployment)**\n",
    "- 모델 성능 평가\n",
    "- 결과 검증\n",
    "- 개선 및 확산\n",
    "- ⇒ 구현된 시스템을 평가하고 개선\n",
    "\n",
    "논리적 흐름: **계획 → 준비 → 분석 → 구현 → 평가**\n",
    "\n",
    "당연히 \"뭘 할지(기획)\"를 먼저 정하고, 그에 맞춰 데이터를 준비해야 하기 때문에 ③번이 정답이야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513c5ac",
   "metadata": {},
   "source": [
    "# 10. 다음 중 정성적 및 정량적 데이터에 대한 설명으로 옳지 않은 것은?\n",
    "① 정성적 데이터는 질적 데이터를 표현한 것이고, 정량적 데이터는 양적 데이터를 표현한 것이다. \n",
    "\n",
    "② 정량적 데이터는 수치적 데이터이다. \n",
    "\n",
    "③ 정성적 데이터는 정량 데이터의 연속형으로 변환할 수 있다. \n",
    "\n",
    "④ 정량적 데이터는 정량 데이터의 범주형으로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7dde48",
   "metadata": {},
   "source": [
    "## 답: ③\n",
    "\n",
    "## 설명:\n",
    "\n",
    "**정성적(질적) 데이터 vs 정량적(양적) 데이터**\n",
    "\n",
    "**정성적 데이터 (Qualitative Data)** - 범주형\n",
    "- 질적 특성을 나타냄 (①번 맞음)\n",
    "- 수치로 표현 안 됨\n",
    "- 예: 성별(남/여), 색상(빨강/파랑), 만족도(좋음/나쁨)\n",
    "- 종류: 명목형, 순서형\n",
    "\n",
    "**정량적 데이터 (Quantitative Data)** - 수치형\n",
    "- 양적 특성을 나타냄 (①번 맞음)\n",
    "- 수치로 표현됨 (②번 맞음)\n",
    "- 예: 키(170cm), 나이(25세), 온도(20℃)\n",
    "- 종류: 이산형, 연속형\n",
    "\n",
    "**데이터 변환 방향:**\n",
    "\n",
    "✓ **정량 → 정성 (범주형) 변환 가능** (④번 맞음)\n",
    "- 나이(20세) → 연령대(20대)\n",
    "- 점수(85점) → 등급(B)\n",
    "- 연속형을 구간으로 나누어 범주화\n",
    "\n",
    "✗ **정성 → 정량 (연속형) 변환 불가능** (③번 틀림)\n",
    "- 성별(남/여)을 연속형 숫자로 변환할 수 없음\n",
    "- 색상(빨강/파랑)을 연속형으로 변환 불가\n",
    "- One-Hot Encoding 등으로 숫자화는 가능하지만, 이건 연속형이 아니라 여전히 범주형임\n",
    "\n",
    "**③번이 틀린 이유:**\n",
    "정성적 데이터(범주형)는 본질적으로 질적 특성이라 연속적인 수치 값으로 변환할 수 없어. 예를 들어 '빨강'과 '파랑' 사이에 연속적인 값이 존재한다고 볼 수 없잖아. 코딩을 위해 숫자를 부여할 순 있지만(예: 남=0, 여=1), 이건 여전히 범주형이지 연속형이 아니야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfbcc0",
   "metadata": {},
   "source": [
    "# 11. 비정형 데이터로 옳지 않은 것은?\n",
    "① 거래 내역(Transaction) 데이터 \n",
    "\n",
    "② 음성 데이터 \n",
    "\n",
    "③ 이미지 데이터 \n",
    "\n",
    "④ 영상 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e99a6",
   "metadata": {},
   "source": [
    "## 답: ①\n",
    "\n",
    "## 설명:\n",
    "데이터는 구조화 정도에 따라 3가지로 분류돼:\n",
    "\n",
    "**1. 정형 데이터 (Structured Data)**\n",
    "- 고정된 스키마(구조)를 가진 데이터\n",
    "- 행과 열로 구성된 테이블 형태\n",
    "- 예: **거래 내역 데이터**, 고객 정보, 재고 데이터\n",
    "- 저장: 관계형 데이터베이스(RDBMS)\n",
    "- 분석: SQL로 쉽게 처리 가능\n",
    "\n",
    "**2. 반정형 데이터 (Semi-Structured Data)**\n",
    "- 일정한 구조는 있지만 테이블 형태는 아님\n",
    "- 예: JSON, XML, HTML, 로그 파일\n",
    "- 메타데이터나 태그로 구조 표현\n",
    "\n",
    "**3. 비정형 데이터 (Unstructured Data)**\n",
    "- 정해진 구조가 없는 데이터\n",
    "- 예: \n",
    "  - ② 음성 데이터 (오디오 파일)\n",
    "  - ③ 이미지 데이터 (사진, 그림)\n",
    "  - ④ 영상 데이터 (동영상)\n",
    "  - 텍스트 문서, 이메일, SNS 게시글\n",
    "\n",
    "**①번이 틀린 이유:**\n",
    "**거래 내역(Transaction) 데이터**는 전형적인 **정형 데이터**야. \n",
    "\n",
    "거래 내역 테이블 구조 예시:\n",
    "```\n",
    "거래ID | 고객ID | 상품명   | 수량 | 금액  | 거래일시\n",
    "------------------------------------------------\n",
    "T001  | C123  | 노트북   | 1   | 1500 | 2025-01-21\n",
    "T002  | C456  | 마우스   | 2   | 30   | 2025-01-21\n",
    "```\n",
    "\n",
    "이렇게 명확한 스키마를 가진 테이블 형태이므로 정형 데이터야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418c1b6",
   "metadata": {},
   "source": [
    "# 12. 데이터와 변수에 대한 관계로 잘못 짝지어진 것은?\n",
    "① 연령 - 비율변수 \n",
    "\n",
    "② 성별 - 명목변수 \n",
    "\n",
    "③ 매출액 - 서열변수 \n",
    "\n",
    "④ 온도 - 등간변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02784bed",
   "metadata": {},
   "source": [
    "## 답: ③\n",
    "\n",
    "## 설명:\n",
    "변수의 척도 수준은 4가지로 구분돼:\n",
    "\n",
    "**1. 명목척도 (Nominal Scale)**\n",
    "- 분류 목적, 순서 없음\n",
    "- 예: **성별**(남/여), 혈액형(A/B/O/AB), 지역 (②번 맞음)\n",
    "- 가능 연산: =, ≠\n",
    "\n",
    "**2. 서열척도 (Ordinal Scale)**\n",
    "- 순서 의미 있음, 간격은 의미 없음\n",
    "- 예: 학년(1학년<2학년<3학년), 만족도(매우불만<불만<보통<만족<매우만족), 등수\n",
    "- 가능 연산: =, ≠, <, >\n",
    "- **매출액은 서열변수가 아니야!** (③번 틀림)\n",
    "\n",
    "**3. 등간척도 (Interval Scale)**\n",
    "- 순서와 간격 모두 의미 있음\n",
    "- 절대 0점이 없음 (0이 없음을 의미하지 않음)\n",
    "- 예: **온도**(섭씨, 화씨), 지능지수(IQ) (④번 맞음)\n",
    "- 가능 연산: =, ≠, <, >, +, -\n",
    "- 0℃가 온도가 없다는 의미는 아니지?\n",
    "\n",
    "**4. 비율척도 (Ratio Scale)**\n",
    "- 순서, 간격, 절대 0점 모두 의미 있음\n",
    "- 예: **연령**, **매출액**, 키, 몸무게, 거리 (①번 맞음)\n",
    "- 가능 연산: =, ≠, <, >, +, -, ×, ÷\n",
    "- 0세는 나이가 0이라는 절대적 의미\n",
    "- 0원은 매출이 없다는 절대적 의미\n",
    "\n",
    "**③번이 틀린 이유:**\n",
    "**매출액**은 절대 0점이 있고(매출 0원), 비율 연산이 가능해(매출 200만원은 100만원의 2배). 따라서 서열변수가 아니라 **비율변수**야.\n",
    "\n",
    "서열변수는 \"1등과 2등 사이 간격\"과 \"2등과 3등 사이 간격\"이 같다고 볼 수 없는데, 매출액은 100만원과 200만원 사이 간격이 명확히 100만원이므로 비율변수지."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacbb00",
   "metadata": {},
   "source": [
    "# 13. 데이터 변환에 대한 설명으로 가장 옳은 것은?\n",
    "① 금융 데이터에서 이상거래를 감지해 데이터 분포를 매끄럽게 만듦 - 정규화 \n",
    "\n",
    "② 연령을 기준으로 10~30은 청년, 40~60은 중년으로 나눔 - 범주화 \n",
    "\n",
    "③ 데이터가 가지고 있는 특성의 개수를 줄임 - 표준화 \n",
    "\n",
    "④ 딥러닝 모델에서 이미지를 학습할 때, 이미지 데이터를 [0, 1] 범위 변환 - 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d795150",
   "metadata": {},
   "source": [
    "## 답: ②\n",
    "\n",
    "## 설명:\n",
    "데이터 변환 기법들을 정리해보면:\n",
    "\n",
    "**각 선택지 분석:**\n",
    "\n",
    "**① 이상거래 감지 → 평활화(Smoothing)**\n",
    "- 정규화(Normalization)가 아님\n",
    "- 이상치 제거나 평활화 기법에 해당\n",
    "- 정규화는 데이터 범위를 조정하는 거야\n",
    "\n",
    "**② 연령 구간화 → 범주화(Binning/Discretization)** ✓ 정답!\n",
    "- 연속형 변수를 범주형으로 변환\n",
    "- 예: \n",
    "  - 나이(25) → 연령대(청년)\n",
    "  - 점수(85) → 등급(B)\n",
    "- 올바른 설명!\n",
    "\n",
    "**③ 특성 개수 줄이기 → 차원 축소(Dimensionality Reduction)**\n",
    "- 표준화(Standardization)가 아님\n",
    "- 표준화는 평균 0, 표준편차 1로 변환: z = (x-μ)/σ\n",
    "- 차원 축소 예: PCA, t-SNE\n",
    "\n",
    "**④ [0,1] 범위 변환 → 정규화(Normalization)**\n",
    "- 일반화(Generalization)가 아님\n",
    "- 정규화(Min-Max Scaling): x' = (x-min)/(max-min)\n",
    "- 일반화는 모델이 새로운 데이터에 잘 적용되는 능력을 의미\n",
    "\n",
    "**데이터 변환 기법 정리:**\n",
    "\n",
    "1. **정규화(Normalization)**: 데이터를 특정 범위[0,1]로 조정\n",
    "2. **표준화(Standardization)**: 평균 0, 표준편차 1로 조정\n",
    "3. **범주화(Binning)**: 연속형을 범주형으로 변환\n",
    "4. **차원 축소**: 변수/특성 개수 줄이기\n",
    "5. **평활화(Smoothing)**: 노이즈 제거, 분포를 매끄럽게"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d9154",
   "metadata": {},
   "source": [
    "# 14. 가명처리 기법에서 순서를 섞어 개인정보를 알아볼 수 없게 하는 것은?\n",
    "① 가명처리 - 휴리스틱 익명화 \n",
    "\n",
    "② 총계처리 - 재배열 \n",
    "\n",
    "③ 일반화 - 마스킹 \n",
    "\n",
    "④ 최소화 - 잡음(Noise) 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65310520",
   "metadata": {},
   "source": [
    "## 답: ②\n",
    "\n",
    "## 설명:\n",
    "가명처리 기법들을 정리해보면:\n",
    "\n",
    "**가명처리 기법 분류:**\n",
    "\n",
    "**1. 가명처리**\n",
    "- 휴리스틱 익명화: 규칙 기반 변환\n",
    "- 암호화: 암호 알고리즘으로 변환\n",
    "- 교환방법(Swapping): 다른 개인의 데이터와 교환\n",
    "\n",
    "**2. 총계처리 (Aggregation)**\n",
    "- **재배열(Permutation/Shuffling)**: 순서를 무작위로 섞음 ← 정답!\n",
    "- 부분 총계: 일부만 합산\n",
    "- 라운딩(Rounding): 반올림 처리\n",
    "- 예: 주민번호를 무작위로 재배열해서 원래 사람과 매칭 불가능하게 만듦\n",
    "\n",
    "**3. 데이터 삭제 (Data Reduction)**\n",
    "- 식별자 삭제: 직접 식별 정보 제거\n",
    "- 레코드 삭제: 특정 행 전체 삭제\n",
    "- 식별요소 전부 삭제: 준식별자까지 모두 삭제\n",
    "\n",
    "**4. 일반화 (Generalization)**\n",
    "- 감추기(Suppression): 특정 값을 제거 또는 * 처리\n",
    "- **마스킹(Masking)**: 일부를 * 등으로 대체\n",
    "- 예: 010-1234-5678 → 010-****-5678\n",
    "\n",
    "**5. 범주화**\n",
    "- 임의 잡음 추가: 원본에 랜덤 노이즈 추가\n",
    "- 공백과 대체: 빈 값으로 대체\n",
    "\n",
    "**②번이 정답인 이유:**\n",
    "\"순서를 섞어 개인정보를 알아볼 수 없게 하는 것\"은 **총계처리의 재배열(Shuffling/Permutation)** 기법이야. \n",
    "\n",
    "예를 들어:\n",
    "```\n",
    "원본:\n",
    "이름    나이\n",
    "김철수  30\n",
    "이영희  25\n",
    "박민수  35\n",
    "\n",
    "재배열 후:\n",
    "이름    나이\n",
    "김철수  35  <- 순서가 섞임\n",
    "이영희  30  <- 원래 매칭이 깨짐\n",
    "박민수  25\n",
    "```\n",
    "\n",
    "통계적 분포는 유지되지만 개인별 정확한 정보는 알 수 없게 돼."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186dfb5",
   "metadata": {},
   "source": [
    "# 15. 데이터 마스킹(Data Masking)에 대한 설명으로 가장 옳지 않은 것은?\n",
    "① 데이터 마스킹을 철저히 하면 데이터가 삭제될 수 있다. \n",
    "\n",
    "② 데이터 마스킹 수준이 높으면 데이터를 식별, 예측하기 쉬워진다.\n",
    "\n",
    "③ 데이터 마스킹은 개인 식별 요소를 제거하는 것이 가능하며, 원 데이터 구조에 대한 변형이 적다는 장점이 있다. \n",
    "\n",
    "④ 데이터 마스킹을 과도하게 적용할 경우 데이터 필요 목적에 활용하기 어려우며, 수준이 낮을 경우 특정한 값에 대한 추론이 가능하다는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064dcd42",
   "metadata": {},
   "source": [
    "## 답: ②\n",
    "\n",
    "## 설명:\n",
    "**데이터 마스킹(Data Masking)**은 민감한 데이터의 일부를 가려서 보호하는 기법이야.\n",
    "\n",
    "**데이터 마스킹 개념:**\n",
    "- 개인정보나 민감 정보를 *, X 등으로 대체\n",
    "- 예: 010-1234-5678 → 010-****-5678\n",
    "- 예: 홍길동 → 홍*동\n",
    "- 예: 991225-1234567 → 991225-*******\n",
    "\n",
    "**각 선택지 분석:**\n",
    "\n",
    "**① 철저한 마스킹 → 데이터 삭제** (맞음)\n",
    "- 마스킹을 극단적으로 하면 사실상 삭제와 같은 효과\n",
    "- 예: 홍길동 → *** (완전 가림 = 삭제와 유사)\n",
    "\n",
    "**② 마스킹 수준이 높으면 식별/예측이 쉬워진다** (틀림!) ← 정답\n",
    "- **완전히 반대야!**\n",
    "- 마스킹 수준이 **높을수록** → 식별/예측이 **어려워짐**\n",
    "- 마스킹 수준이 **낮을수록** → 식별/예측이 **쉬워짐**\n",
    "- 예:\n",
    "  - 낮은 마스킹: 010-1234-56** → 추론 가능\n",
    "  - 높은 마스킹: 010-****-**** → 추론 불가능\n",
    "\n",
    "**③ 장점: 구조 변형 적음** (맞음)\n",
    "- 데이터 형식은 유지됨 (전화번호는 여전히 전화번호 형태)\n",
    "- 데이터 타입, 길이 등 구조는 그대로\n",
    "- 시스템 호환성 유지 가능\n",
    "\n",
    "**④ 마스킹의 단점** (맞음)\n",
    "- **과도한 마스킹**: 데이터 활용가치 저하\n",
    "  - 예: 010-****-**** → 통계 분석 불가\n",
    "- **부족한 마스킹**: 개인정보 유출 위험\n",
    "  - 예: 010-1234-567* → 1개만 가려서 추론 가능\n",
    "\n",
    "**마스킹 수준의 트레이드오프:**\n",
    "```\n",
    "마스킹 수준 ↑ → 보안성 ↑, 활용성 ↓, 식별가능성 ↓\n",
    "마스킹 수준 ↓ → 보안성 ↓, 활용성 ↑, 식별가능성 ↑\n",
    "```\n",
    "\n",
    "따라서 ②번이 틀렸어. 마스킹 수준이 높아질수록 데이터 식별과 예측은 더 어려워져야 정상이야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f1a57",
   "metadata": {},
   "source": [
    "# 16. 데이터 웨어하우스(Data Warehouse)에 대한 특징으로 옳지 않은 것은?\n",
    "① 휘발성(Volatile) \n",
    "\n",
    "② 주제 지향적(Subject-oriented) \n",
    "\n",
    "③ 통합적(Integrated)\n",
    "\n",
    "④ 시계열적(Time-series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c3389",
   "metadata": {},
   "source": [
    "## 답: ①\n",
    "\n",
    "## 설명:\n",
    "**데이터 웨어하우스(DW)**는 의사결정 지원을 위한 통합 데이터 저장소야.\n",
    "\n",
    "**데이터 웨어하우스의 4가지 핵심 특징:**\n",
    "\n",
    "**1. 주제 지향적 (Subject-Oriented)** (②번 맞음)\n",
    "- 업무 프로세스가 아닌 **주제(고객, 상품, 판매 등) 중심**으로 구성\n",
    "- 예: \"고객\" 주제로 여러 시스템의 고객 데이터를 통합\n",
    "- 분석과 의사결정에 최적화\n",
    "\n",
    "**2. 통합적 (Integrated)** (③번 맞음)\n",
    "- 여러 소스의 데이터를 **일관된 형식으로 통합**\n",
    "- 데이터 형식, 코드, 용어를 표준화\n",
    "- 예: \n",
    "  - 시스템A의 \"M/F\" → \"남/여\"\n",
    "  - 시스템B의 \"남성/여성\" → \"남/여\"\n",
    "  - 통합하여 \"남/여\"로 표준화\n",
    "\n",
    "**3. 시계열적/시간변동성 (Time-Variant)** (④번 맞음)\n",
    "- **과거 데이터를 시간에 따라 저장**\n",
    "- 특정 시점의 스냅샷 보관\n",
    "- 시간 흐름에 따른 변화 분석 가능\n",
    "- 예: 2020년 매출, 2021년 매출, 2022년 매출 비교\n",
    "\n",
    "**4. 비휘발성 (Non-Volatile)** (①번 틀림!)\n",
    "- 데이터가 **한번 저장되면 삭제되거나 수정되지 않음**\n",
    "- 읽기 전용(Read-Only)\n",
    "- 오직 적재(Load)와 조회(Access)만 가능\n",
    "- 데이터의 역사적 기록 보존\n",
    "\n",
    "**①번이 틀린 이유:**\n",
    "DW의 특징은 **비휘발성(Non-Volatile)**이야. 문제에서는 **휘발성(Volatile)**이라고 했으니까 반대 개념이지.\n",
    "\n",
    "**휘발성 vs 비휘발성:**\n",
    "- **휘발성(Volatile)**: 데이터가 계속 바뀜, 업데이트/삭제 가능 (OLTP 시스템)\n",
    "- **비휘발성(Non-Volatile)**: 데이터가 안 바뀜, 추가만 가능 (DW)\n",
    "\n",
    "**데이터 웨어하우스 vs 운영 DB 비교:**\n",
    "```\n",
    "운영 DB (OLTP)          데이터 웨어하우스 (OLAP)\n",
    "- 트랜잭션 처리         - 의사결정 지원\n",
    "- 실시간 업데이트       - 주기적 적재\n",
    "- 휘발성 (갱신/삭제)   - 비휘발성 (읽기 전용)\n",
    "- 정규화               - 비정규화 (성능 최적화)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504161d7",
   "metadata": {},
   "source": [
    "# 17. 다음 중 분산파일시스템으로 옳지 않은 것은?\n",
    "① Hbase \n",
    "\n",
    "② Ceph \n",
    "\n",
    "③ HDFS \n",
    "\n",
    "④ GFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851f4f3",
   "metadata": {},
   "source": [
    "## 답: ①\n",
    "\n",
    "## 설명:\n",
    "**분산 파일 시스템(Distributed File System, DFS)**은 여러 서버에 파일을 분산 저장하고 관리하는 시스템이야.\n",
    "\n",
    "**각 선택지 분석:**\n",
    "\n",
    "**① HBase** - **분산 데이터베이스** (틀림!) ← 정답\n",
    "- Apache HBase는 **분산 NoSQL 데이터베이스**\n",
    "- 파일 시스템이 아니라 **컬럼 기반 데이터베이스**\n",
    "- Hadoop 위에서 동작하며 HDFS를 사용하긴 하지만, 그 자체는 파일 시스템이 아님\n",
    "- Google BigTable을 모델로 만들어짐\n",
    "- 용도: 대용량 실시간 읽기/쓰기 처리\n",
    "\n",
    "**② Ceph** - 분산 파일 시스템 (맞음)\n",
    "- 오픈소스 분산 스토리지 시스템\n",
    "- 객체 스토리지, 블록 스토리지, 파일 시스템 모두 지원\n",
    "- 높은 확장성과 내결함성\n",
    "- RedHat에서 지원\n",
    "\n",
    "**③ HDFS (Hadoop Distributed File System)** - 분산 파일 시스템 (맞음)\n",
    "- Hadoop의 핵심 컴포넌트\n",
    "- 대용량 파일을 블록 단위로 분산 저장\n",
    "- NameNode(메타데이터)와 DataNode(실제 데이터)로 구성\n",
    "- 배치 처리에 최적화\n",
    "- 높은 처리량(throughput)\n",
    "\n",
    "**④ GFS (Google File System)** - 분산 파일 시스템 (맞음)\n",
    "- Google이 개발한 분산 파일 시스템\n",
    "- HDFS의 모델이 됨\n",
    "- 대규모 분산 데이터 처리를 위해 설계\n",
    "- Master-Slave 구조\n",
    "\n",
    "**분산 파일 시스템 vs 분산 데이터베이스:**\n",
    "\n",
    "```\n",
    "분산 파일 시스템          분산 데이터베이스\n",
    "(HDFS, GFS, Ceph)       (HBase, Cassandra, MongoDB)\n",
    "├ 파일 단위 저장         ├ 레코드/문서 단위 저장\n",
    "├ 파일 시스템 API       ├ 데이터베이스 API\n",
    "├ 순차 접근 최적화      ├ 랜덤 접근 지원\n",
    "└ 배치 처리 중심        └ CRUD 연산 지원\n",
    "```\n",
    "\n",
    "**HBase가 분산 파일 시스템이 아닌 이유:**\n",
    "- HBase는 HDFS **위에서** 동작하는 데이터베이스 계층\n",
    "- 파일을 직접 관리하는 게 아니라 테이블/행/열 구조로 데이터 관리\n",
    "- SQL과 유사한 방식으로 데이터 조회 (단, NoSQL이라 SQL은 아님)\n",
    "\n",
    "따라서 ①번 HBase는 분산 파일 시스템이 아니라 분산 데이터베이스야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c5697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
