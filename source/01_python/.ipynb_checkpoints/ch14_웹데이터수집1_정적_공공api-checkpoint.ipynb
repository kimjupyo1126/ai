{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d149acd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:22pt;}\n",
       "div.text_cell_render.rendered_html{font-size:18pt;}\n",
       "div.text_cell_render ul li pre{font-size:22pt; line-height:30px;}\n",
       "div.output {font-size:22pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:22pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:22pt;padding:5px;}\n",
       "table.dataframe{font-size:22px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:99% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:22pt;}\n",
    "div.text_cell_render.rendered_html{font-size:18pt;}\n",
    "div.text_cell_render ul li pre{font-size:22pt; line-height:30px;}\n",
    "div.output {font-size:22pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:22pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:22pt;padding:5px;}\n",
    "table.dataframe{font-size:22px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd703c9",
   "metadata": {},
   "source": [
    "<b><font size=\"7\" color=\"red\">ch14. 웹데이터 수집</font></b>\n",
    "# 1절. BeautifulSoup과 parser\n",
    "`pip install bs4` 아나콘다를 설치하면 자동 설치되는 패키지 7500개에 포함\n",
    "\n",
    "- 공식 Documentation : https://beautiful-soup-4.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0a5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 local PC의 파일을 url(http://~)처럼 접근\n",
    "import requests # http 요청 처리하는 lib\n",
    "from requests_file import FileAdapter # file://프로토콜을 다루기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa406af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = requests.Session() # HTTP 요청처리하는 세션 객체\n",
    "s.mount(\"file://\", FileAdapter())\n",
    "# file://경로로 들어오면 이 요청은 c:(로컬파일)을 접근\n",
    "response = s.get('file:///ai/lecNote/01_python/data/ch14_sample.html')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f826a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘 접근하였습니다.\n"
     ]
    }
   ],
   "source": [
    "if response:\n",
    "    print('잘 접근하였습니다.')\n",
    "else:\n",
    "    print('접근을 못했습니다')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23204ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code\n",
    "    # 200 : 정상\n",
    "    # 404 : 없는페이지\n",
    "    # 406 : get, post 오류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfef3c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90 \\xec\\x95\\x88\\xec\\x9d\\x98 \\xeb\\x82\\xb4\\xec\\x9a\\xa9</div>\\r\\n  <p>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90\\xec\\x84\\x9c \\xed\\x99\\x9c\\xec\\x9a\\xa9\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</p>\\r\\n  <div class=\"contents\">\\r\\n    \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\xa5\\xbc \\xec\\x96\\xb4\\xeb\\x96\\xbb\\xea\\xb2\\x8c \\xec\\x9e\\x91\\xec\\x84\\xb1\\xed\\x95\\x98\\xeb\\x8a\\x90\\xeb\\x83\\x90\\xec\\x97\\x90 \\xeb\\x94\\xb0\\xeb\\x9d\\xbc\\r\\n    <span>\\xeb\\x8b\\xa4\\xeb\\xa5\\xb8<b>\\xec\\x9a\\x94\\xec\\x86\\x8c\\xea\\xb0\\x80 \\xeb\\xb0\\x98\\xed\\x99\\x98</b></span>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4\\r\\n  </div>\\r\\n  <div>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90 <b>\\xed\\x99\\x9c\\xec\\x9a\\xa9</b>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content # 바이너리 형식의 html내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb77174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n  <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n  <div class=\"contents\">\\r\\n    선택자를 어떻게 작성하느냐에 따라\\r\\n    <span>다른<b>요소가 반환</b></span>됩니다\\r\\n  </div>\\r\\n  <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d507b9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n  <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n  <div class=\"contents\">\\r\\n    선택자를 어떻게 작성하느냐에 따라\\r\\n    <span>다른<b>요소가 반환</b></span>됩니다\\r\\n  </div>\\r\\n  <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text # HTML파일의 텍스트 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f9d6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 파싱\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, # response.text\n",
    "                    \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6c3501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "el.text : Hello, CSS\n",
      "el.string : Hello, CSS\n",
      "el의 속성들 : {'class': ['greeting', 'css'], 'id': 'text'}\n",
      "el의 id속성 : text\n",
      "el의 id속성 : text\n",
      "el의 href속성 : None\n",
      "el의 태그이름 : h1\n"
     ]
    }
   ],
   "source": [
    "# soup.select_one('선택자') : 해당선택자 처음 하나만\n",
    "el = soup.select_one('h1') # 처음 나오는 h1태그 하나만\n",
    "print('el :', el)\n",
    "print('el.text :', el.text)\n",
    "print('el.string :', el.string)\n",
    "print('el의 속성들 :', el.attrs)\n",
    "print('el의 id속성 :', el.attrs['id']) # el.attrs은 딕셔너리\n",
    "print('el의 id속성 :', el.attrs.get('id'))\n",
    "print('el의 href속성 :', el.attrs.get('href'))\n",
    "print('el의 태그이름 :', el.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f83ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "els : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "els의 text들 : ['Hello, CSS', 'Hi, CSS']\n",
      "els의 string들 : ['Hello, CSS', 'Hi, CSS']\n",
      "els의 속성들 : [{'class': ['greeting', 'css'], 'id': 'text'}, {'class': ['css']}]\n",
      "els의 class 속성들 : [['greeting', 'css'], ['css']]\n"
     ]
    }
   ],
   "source": [
    "# soup.select('선택자') : 해당 선택자 모두 \n",
    "els = soup.select('h1') # h1태그를 list\n",
    "print('els :', els)\n",
    "print('els의 text들 :', [el.text for el in els])\n",
    "print('els의 string들 :', [el.string for el in els])\n",
    "print('els의 속성들 :', [el.attrs for el in els])\n",
    "print('els의 class 속성들 :', [el.attrs.get('class') for el in els])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f232b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_one : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "\n",
      "select_one : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n"
     ]
    }
   ],
   "source": [
    "# soup.find(태그, 속성) : soup.select_one('선택자')와 유사\n",
    "print('select_one :', soup.select_one('h1.css') )\n",
    "print('find :', soup.find('h1', {'class':'css'}) ) # soup.select_one('h1.css')\n",
    "print('find :', soup.find('h1', class_='css') )\n",
    "print()\n",
    "print('select_one :', soup.select_one('h1#text') )\n",
    "print('find :', soup.find('h1', {'id':'text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb422bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n"
     ]
    }
   ],
   "source": [
    "# soup.find_all(태그, 속성) : soup.select('선택자')와 유사\n",
    "print('select :', soup.select('h1.css'))\n",
    "print('find_all :', soup.find_all('h1', class_='css'))\n",
    "print('find_all :', soup.find_all('h1', {'class':'css'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e23db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n"
     ]
    }
   ],
   "source": [
    "print('select :', soup.select('h1.css, span'))\n",
    "print('find_all :', soup.find_all(['h1', 'span'], {'class':'css'}))\n",
    "print('find_all :', soup.find_all('h1', class_='css') + \\\n",
    "                     soup.find_all('span'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee18cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select(빈 list) : []\n",
      "select_one(None) : None\n",
      "find_all(빈 list) : []\n",
      "find(None) : None\n"
     ]
    }
   ],
   "source": [
    "# 없는 엘리먼트 찾기\n",
    "print('select(빈 list) :', soup.select('a.css'))\n",
    "print('select_one(None) :', soup.select_one('a.css'))\n",
    "print('find_all(빈 list) :', soup.find_all('a', {'class', 'css'}))\n",
    "print('find(None) :', soup.find('a', {'class':'css'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5d684",
   "metadata": {},
   "source": [
    "# 2절. 정적 웹 데이터 수집(정적 웹크롤링)\n",
    "## 2.1 BeautifulSoup을 활용한 html 웹 데이터수집\n",
    "### 1) 환율정보 가져오기 ( 네이버증권 -> 시장지표)\n",
    "- https://finance.naver.com/marketindex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bcb6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 허용범위는 사이트마다 ~/robots.txt에서 확인\n",
    "    # Allow : / - 사이트의 모든 경로(/)에 대한 크롤링 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e498de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "response = requests.get(url)\n",
    "# response.status_code\n",
    "# response.text / response.content.decode('cp949')\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "984f5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "response = urlopen(url)\n",
    "response.status\n",
    "# response.read() / response.read().decode('cp949')\n",
    "soup = BeautifulSoup(response, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e7bf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1465.0, 950.16, 1692.73, 205.66, 154.12, 1.1563, 1.3166, 99.46, 60.13, 1702.93, 4122.0, 194583.69]\n"
     ]
    }
   ],
   "source": [
    "# div.head_info > span.value (find함수)\n",
    "prices = []\n",
    "headinfos = soup.find_all('div', class_='head_info')\n",
    "for headinfo in headinfos:\n",
    "    price = headinfo.find('span', class_='value')\n",
    "    # print(price.text.replace(',', ''))\n",
    "    prices.append(float(''.join(price.text.split(',') ) ) )\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "228648e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1465.0, 950.16, 1692.73, 205.66, 154.12, 1.1563, 1.3166, 99.46, 60.13, 1702.93, 4122.0, 194583.69]\n"
     ]
    }
   ],
   "source": [
    "# div.head_info > span.value (select함수)\n",
    "prices = soup.select('div.head_info > span.value')\n",
    "print([float(p.text.replace(',','')) for p in prices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a635bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD\t일본 JPY(100엔)\t유럽연합 EUR\t중국 CNY\t달러/일본 엔\t유로/달러\t영국 파운드/달러\t달러인덱스\tWTI\t휘발유\t국제 금\t국내 금\t"
     ]
    }
   ],
   "source": [
    "titles = soup.select('h3.h_lst > span.blind')\n",
    "for t in titles:\n",
    "        print(t.text, end='\\t')\n",
    "#print([t.text+'\\t' for t in titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb3acf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['원', '원', '원', '원', '엔', '달러', '달러', '', '달러', '원', '달러', '원']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = soup.select('div.head_info > span > span.blind')\n",
    "units = [unit.text for unit in units]\n",
    "units.insert(7, '') # 7번째에 '' 추가\n",
    "units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a19f8306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상승\t상승\t상승\t상승\t상승\t하락\t상승\t하락\t상승\t상승\t상승\t상승\t"
     ]
    }
   ],
   "source": [
    "statuses = soup.select('div.head_info > span.blind')\n",
    "for idx in range(len(statuses)):\n",
    "    print(statuses[idx].text, end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ac09c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 12, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles), len(prices), len(units), len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0fe50c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,465.00원 - 상승\n",
      "일본 JPY(100엔) : 950.16원 - 상승\n",
      "유럽연합 EUR : 1,692.73원 - 상승\n",
      "중국 CNY : 205.66원 - 상승\n",
      "달러/일본 엔 : 154.1200엔 - 상승\n",
      "유로/달러 : 1.1563달러 - 하락\n",
      "영국 파운드/달러 : 1.3166달러 - 상승\n",
      "달러인덱스 : 99.4600 - 하락\n",
      "WTI : 60.13달러 - 상승\n",
      "휘발유 : 1702.93원 - 상승\n",
      "국제 금 : 4122.0달러 - 상승\n",
      "국내 금 : 194583.69원 - 상승\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(titles)):\n",
    "    print(\"{} : {}{} - {}\".format(titles[idx].text,\n",
    "                                 prices[idx].text,\n",
    "                                 units[idx],\n",
    "                                 statuses[idx].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "311be2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,465.00원 -상승\n",
      "일본 JPY(100엔) : 950.16원 -상승\n",
      "유럽연합 EUR : 1,692.73원 -상승\n",
      "중국 CNY : 205.66원 -상승\n",
      "달러/일본 엔 : 154.1200엔 -상승\n",
      "유로/달러 : 1.1563달러 -하락\n",
      "영국 파운드/달러 : 1.3166달러 -상승\n",
      "달러인덱스 : 99.4600 -하락\n",
      "WTI : 60.13달러 -상승\n",
      "휘발유 : 1702.93원 -상승\n",
      "국제 금 : 4122.0달러 -상승\n",
      "국내 금 : 194583.69원 -상승\n"
     ]
    }
   ],
   "source": [
    "for title, price, unit, status in zip(titles, prices, units, statuses):\n",
    "    print(\"{} : {}{} -{}\".format(title.text,\n",
    "                                price.text,\n",
    "                                unit,\n",
    "                                status.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48299508",
   "metadata": {},
   "source": [
    "### 2)이번주 로또 번호 출력\n",
    "- https://dhlottery.co.kr/gameResult.do?method=byWin (google에 로또번호 당첨번호 검색)\n",
    "```\n",
    "    1197회(2025년 11월 08일 추첨)\n",
    "    당첨번호 [1, 5, 7, 26, 28, 43]\n",
    "    보너스 30\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff2c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4589da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin'\n",
    "response = urlopen(url)\n",
    "response.status\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d54fecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = soup.select_one('div.win_result strong').text # 1197회\n",
    "date  = soup.select_one('div.win_result > p.desc').text\n",
    "# date = soup.find('p', class_='desc').text\n",
    "lotto_number_el = soup.select('div.num.win span')\n",
    "lotto_number = [int(el.text) for el in lotto_number_el]\n",
    "bonus_number = int(soup.select_one('div.num.bonus > p > span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "438b6b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197회 (2025년 11월 08일 추첨)\n",
      "당첨번호  [1, 5, 7, 26, 28, 43]\n",
      "보 너 스  30\n"
     ]
    }
   ],
   "source": [
    "print(times, date)\n",
    "print('당첨번호 ',lotto_number)\n",
    "print('보 너 스 ', bonus_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd106482",
   "metadata": {},
   "source": [
    "### 3) 다음 검색 리스트\n",
    "```\n",
    "no title               link\n",
    "0  한풀 꺾인 비트코인  https://v.daum.net/v/20251110094711892\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bbf63cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=비트코인\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>비트코인, ‘셧다운 해제 초읽기’ 10만5000달러…리플 ETF 기대 8% 급등 ...</td>\n",
       "      <td>http://v.daum.net/v/20251111080148418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?</td>\n",
       "      <td>http://v.daum.net/v/20251111161648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>비트코인 기부 이어가는 김거석 씨…서울대병원에도 '1비트코인'</td>\n",
       "      <td>http://v.daum.net/v/20251111103911922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"금보다 싸다?\"…비트코인 5만6000달러 vs 20만달러 '분분'</td>\n",
       "      <td>http://v.daum.net/v/20251111055113522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증</td>\n",
       "      <td>http://v.daum.net/v/20251111140546725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>또 1비트코인 기부한 78세 김거석 씨...이번엔 서울대병원에</td>\n",
       "      <td>http://v.daum.net/v/20251111144111679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>서울대병원에 '1 비트코인' 기부한 70대...\"시대에 맞는 기부도구\"</td>\n",
       "      <td>http://v.daum.net/v/20251111110501306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>\"비트코인 21억 간다더니\"...갑자기 말 바꿨다</td>\n",
       "      <td>http://v.daum.net/v/20251109105545139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>“새로운 기부 도구”…비트코인 1개 서울대병원에 기부한 이 남자</td>\n",
       "      <td>http://v.daum.net/v/20251111105111503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0   비트코인, ‘셧다운 해제 초읽기’ 10만5000달러…리플 ETF 기대 8% 급등 ...   \n",
       "1   1             꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?    \n",
       "2   2                비트코인 기부 이어가는 김거석 씨…서울대병원에도 '1비트코인'    \n",
       "3   3                       \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "4   4             \"금보다 싸다?\"…비트코인 5만6000달러 vs 20만달러 '분분'    \n",
       "5   5          비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증    \n",
       "6   6                또 1비트코인 기부한 78세 김거석 씨...이번엔 서울대병원에    \n",
       "7   7           서울대병원에 '1 비트코인' 기부한 70대...\"시대에 맞는 기부도구\"    \n",
       "8   8                       \"비트코인 21억 간다더니\"...갑자기 말 바꿨다    \n",
       "9   9               “새로운 기부 도구”…비트코인 1개 서울대병원에 기부한 이 남자    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251111080148418  \n",
       "1  http://v.daum.net/v/20251111161648648  \n",
       "2  http://v.daum.net/v/20251111103911922  \n",
       "3  http://v.daum.net/v/20251110094711892  \n",
       "4  http://v.daum.net/v/20251111055113522  \n",
       "5  http://v.daum.net/v/20251111140546725  \n",
       "6  http://v.daum.net/v/20251111144111679  \n",
       "7  http://v.daum.net/v/20251111110501306  \n",
       "8  http://v.daum.net/v/20251109105545139  \n",
       "9  http://v.daum.net/v/20251111105111503  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "word = '비트코인'\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "print(url)\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 방법2 : 불가\n",
    "# from urllib.request import urlopen\n",
    "# from urllib.parse import quote\n",
    "# word = quote('비트코인') # url에 한글이 포함된 경우 한글을 quote()로 변환\n",
    "# url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "# print(url)\n",
    "# response = urlopen(url)\n",
    "# soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "items_find_list = [] # 검색한 결과를 담을 리스트(딕셔너리 list)\n",
    "items_el = soup.select('div.item-title > strong.tit-g > a')\n",
    "for idx, item in enumerate(items_el):\n",
    "    # print(idx, item.text, item.attrs.get('href'))\n",
    "    items_find_list.append({'no':idx,\n",
    "                           'title':item.text,\n",
    "                           'link':item.attrs.get('href')})\n",
    "import pandas as pd\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f5b4868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>번호</th>\n",
       "      <th>제목</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>비트코인, ‘셧다운 해제 초읽기’ 10만5000달러…리플 ETF 기대 8% 급등 ...</td>\n",
       "      <td>http://v.daum.net/v/20251111080148418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?</td>\n",
       "      <td>http://v.daum.net/v/20251111161648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>비트코인 기부 이어가는 김거석 씨…서울대병원에도 '1비트코인'</td>\n",
       "      <td>http://v.daum.net/v/20251111103911922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"금보다 싸다?\"…비트코인 5만6000달러 vs 20만달러 '분분'</td>\n",
       "      <td>http://v.daum.net/v/20251111055113522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증</td>\n",
       "      <td>http://v.daum.net/v/20251111140546725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>또 1비트코인 기부한 78세 김거석 씨...이번엔 서울대병원에</td>\n",
       "      <td>http://v.daum.net/v/20251111144111679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>서울대병원에 '1 비트코인' 기부한 70대...\"시대에 맞는 기부도구\"</td>\n",
       "      <td>http://v.daum.net/v/20251111110501306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>\"비트코인 21억 간다더니\"...갑자기 말 바꿨다</td>\n",
       "      <td>http://v.daum.net/v/20251109105545139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>“새로운 기부 도구”…비트코인 1개 서울대병원에 기부한 이 남자</td>\n",
       "      <td>http://v.daum.net/v/20251111105111503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   번호                                                 제목  \\\n",
       "0   0   비트코인, ‘셧다운 해제 초읽기’ 10만5000달러…리플 ETF 기대 8% 급등 ...   \n",
       "1   1             꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?    \n",
       "2   2                비트코인 기부 이어가는 김거석 씨…서울대병원에도 '1비트코인'    \n",
       "3   3                       \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "4   4             \"금보다 싸다?\"…비트코인 5만6000달러 vs 20만달러 '분분'    \n",
       "5   5          비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증    \n",
       "6   6                또 1비트코인 기부한 78세 김거석 씨...이번엔 서울대병원에    \n",
       "7   7           서울대병원에 '1 비트코인' 기부한 70대...\"시대에 맞는 기부도구\"    \n",
       "8   8                       \"비트코인 21억 간다더니\"...갑자기 말 바꿨다    \n",
       "9   9               “새로운 기부 도구”…비트코인 1개 서울대병원에 기부한 이 남자    \n",
       "\n",
       "                                      링크  \n",
       "0  http://v.daum.net/v/20251111080148418  \n",
       "1  http://v.daum.net/v/20251111161648648  \n",
       "2  http://v.daum.net/v/20251111103911922  \n",
       "3  http://v.daum.net/v/20251110094711892  \n",
       "4  http://v.daum.net/v/20251111055113522  \n",
       "5  http://v.daum.net/v/20251111140546725  \n",
       "6  http://v.daum.net/v/20251111144111679  \n",
       "7  http://v.daum.net/v/20251111110501306  \n",
       "8  http://v.daum.net/v/20251109105545139  \n",
       "9  http://v.daum.net/v/20251111105111503  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_find_list = [] # 검색한 결과를 담을 리스트\n",
    "items_el = soup.select('div.item-title > strong.tit-g > a')\n",
    "for idx, item in enumerate(items_el):\n",
    "    items_find_list.append([idx, item.text, item.attrs['href']])\n",
    "pd.DataFrame(items_find_list, columns=['번호', '제목', '링크'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f21cc47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>비트코인, ‘셧다운 해제 초읽기’ 10만5000달러…리플 ETF 기대 8% 급등 ...</td>\n",
       "      <td>http://v.daum.net/v/20251111080148418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?</td>\n",
       "      <td>http://v.daum.net/v/20251111161648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>비트코인 기부 이어가는 김거석 씨…서울대병원에도 '1비트코인'</td>\n",
       "      <td>http://v.daum.net/v/20251111103911922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"금보다 싸다?\"…비트코인 5만6000달러 vs 20만달러 '분분'</td>\n",
       "      <td>http://v.daum.net/v/20251111055113522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증</td>\n",
       "      <td>http://v.daum.net/v/20251111140546725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>또 1비트코인 기부한 78세 김거석 씨...이번엔 서울대병원에</td>\n",
       "      <td>http://v.daum.net/v/20251111144111679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>서울대병원에 '1 비트코인' 기부한 70대...\"시대에 맞는 기부도구\"</td>\n",
       "      <td>http://v.daum.net/v/20251111110501306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>\"비트코인 21억 간다더니\"...갑자기 말 바꿨다</td>\n",
       "      <td>http://v.daum.net/v/20251109105545139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>“새로운 기부 도구”…비트코인 1개 서울대병원에 기부한 이 남자</td>\n",
       "      <td>http://v.daum.net/v/20251111105111503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                              title  \\\n",
       "0   0   비트코인, ‘셧다운 해제 초읽기’ 10만5000달러…리플 ETF 기대 8% 급등 ...   \n",
       "1   1             꿈틀대던 비트코인, 다시 10.5만달러대…'고래 매도' 조정 신호?    \n",
       "2   2                비트코인 기부 이어가는 김거석 씨…서울대병원에도 '1비트코인'    \n",
       "3   3                       \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "4   4             \"금보다 싸다?\"…비트코인 5만6000달러 vs 20만달러 '분분'    \n",
       "5   5          비트코인 ETF 막힌 한국…서학개미, 미국 레버리지로 '우회 매수' 급증    \n",
       "6   6                또 1비트코인 기부한 78세 김거석 씨...이번엔 서울대병원에    \n",
       "7   7           서울대병원에 '1 비트코인' 기부한 70대...\"시대에 맞는 기부도구\"    \n",
       "8   8                       \"비트코인 21억 간다더니\"...갑자기 말 바꿨다    \n",
       "9   9               “새로운 기부 도구”…비트코인 1개 서울대병원에 기부한 이 남자    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251111080148418  \n",
       "1  http://v.daum.net/v/20251111161648648  \n",
       "2  http://v.daum.net/v/20251111103911922  \n",
       "3  http://v.daum.net/v/20251110094711892  \n",
       "4  http://v.daum.net/v/20251111055113522  \n",
       "5  http://v.daum.net/v/20251111140546725  \n",
       "6  http://v.daum.net/v/20251111144111679  \n",
       "7  http://v.daum.net/v/20251111110501306  \n",
       "8  http://v.daum.net/v/20251109105545139  \n",
       "9  http://v.daum.net/v/20251111105111503  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_find_list = [] # 검색한 결과를 담을 리스트\n",
    "# div.item-title > strong.tit-g > a\n",
    "item_titles = soup.find_all('div', class_='item-title')\n",
    "for idx, item in enumerate(item_titles):\n",
    "    a = item.find('a')\n",
    "    #print(idx, a.text, a.attrs['href'])\n",
    "    #items_find_list.append([idx, a.text, a.attrs['href']])\n",
    "    items_find_list.append({\n",
    "        'no':idx,\n",
    "        'title':a.text,\n",
    "        'link':a.attrs['href'],\n",
    "    })\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "078cf69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 뉴스 검색(원하는 키워드를 원하는 페이지를 가져오기)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def collect_news_list(keyword, page):\n",
    "    'keyword로 page에 다음 뉴스검색한 결과를 출력->list를 return'\n",
    "    #url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}&p={page}'\n",
    "    # response = requests.get(url)\n",
    "    url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8'\n",
    "    params = {'q':keyword, 'p':page}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    items_find_list = [] # 검색한 결과를 담는 리스트\n",
    "    item_titles = soup.select('div.item-title > strong.tit-g > a')\n",
    "    for idx, item in enumerate(item_titles):\n",
    "        items_find_list.append([(page-1)*10+idx, item.text, item.attrs['href']])\n",
    "    return items_find_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83cc431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, ' 인텔 AI 총괄 사친 카티, 오픈AI로 전격 이직 ', 'http://v.daum.net/v/20251111105650791'],\n",
       " [1,\n",
       "  ' [부자들의 투자노트] LG AI연구원 이문태 \"AI 거품 가능성 낮아\" ',\n",
       "  'http://v.daum.net/v/20251111074522130'],\n",
       " [2,\n",
       "  ' [리셋 코리아] AI 대전환기, 소버린AI 도전 피하지 말아야 ',\n",
       "  'http://v.daum.net/v/20251110002138457'],\n",
       " [3,\n",
       "  ' “AI·인간 \\'공동과학자\\' 시대…R&D 속도, AI 활용 능력이 가른다\" ',\n",
       "  'http://v.daum.net/v/20251110050654976'],\n",
       " [4,\n",
       "  \" 초중고 정보 교과 내 AI 교육 확대…모든 교육청 'AI 지원센터' 설립 \",\n",
       "  'http://v.daum.net/v/20251110140139274'],\n",
       " [5, \" AI 거품론에도… 데이터센터 투자 '쑥쑥' \", 'http://v.daum.net/v/20251111041609575'],\n",
       " [6,\n",
       "  ' AI로 안 되는 게 없네…\"오픈AI, 헬스케어 분야 진출 검토\" ',\n",
       "  'http://v.daum.net/v/20251111042100588'],\n",
       " [7,\n",
       "  ' 초중고 ‘전 생애 AI 교육’…‘AI 박사’ 5년 반 만에 키운다 ',\n",
       "  'http://v.daum.net/v/20251110205314501'],\n",
       " [8,\n",
       "  ' \"AI 대전환 이끈다\"...충남도, \\'AI특위\\' 띄웠다 ',\n",
       "  'http://v.daum.net/v/20251111150147845'],\n",
       " [9,\n",
       "  ' 인텔 AI 총괄, 오픈AI로 이적…AI 인재 전쟁 격화 ',\n",
       "  'http://v.daum.net/v/20251111151050344']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_news_list('AI', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53df997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1번째 검색어 청바지 검색 결과 수집 중입니다===\n",
      "===2번째 검색어 동대문 검색 결과 수집 중입니다===\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "keywords = ['청바지', '동대문']\n",
    "result0 = [] # 청바지 1~3페이지까지 검색한 결과를 담을 list\n",
    "result1 = [] # 동대문 1~3페이지까지 검색한 결과를 담을 list\n",
    "pages = 3\n",
    "for i, keyword in enumerate(keywords):\n",
    "    print(f'==={i+1}번째 검색어 {keyword} 검색 결과 수집 중입니다===')\n",
    "    for page in range(1, pages+1):\n",
    "        if i==0:\n",
    "            result0.extend(collect_news_list(keyword, page))\n",
    "        elif i==1:\n",
    "            result1.extend(collect_news_list(keyword, page))\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b003391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>“돈 벌어가세요” 동대문 일요시장, 겨울옷 ‘핫플’ 됐다</td>\n",
       "      <td>http://v.daum.net/v/20251111111251709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“돈 벌어가세요” 동대문 일요시장, 겨울옷 핫플된 사연? [르포]</td>\n",
       "      <td>http://v.daum.net/v/20251110100357735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>노보텔 앰배서더 동대문, 연말 맞아 '페스티브 파티’ 패키지 출시</td>\n",
       "      <td>http://v.daum.net/v/20251111155426418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>동대문구, 11월 학부모·학생 맞춤형 교육 특강</td>\n",
       "      <td>http://v.daum.net/v/20251111151146411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>한국청년회의소·서울동대문JC, 제2회 출생장려사업 개최</td>\n",
       "      <td>http://v.daum.net/v/20251111152547093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                   title  \\\n",
       "0   0        “돈 벌어가세요” 동대문 일요시장, 겨울옷 ‘핫플’ 됐다    \n",
       "1   1   “돈 벌어가세요” 동대문 일요시장, 겨울옷 핫플된 사연? [르포]    \n",
       "2   2   노보텔 앰배서더 동대문, 연말 맞아 '페스티브 파티’ 패키지 출시    \n",
       "3   3             동대문구, 11월 학부모·학생 맞춤형 교육 특강    \n",
       "4   4         한국청년회의소·서울동대문JC, 제2회 출생장려사업 개최    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251111111251709  \n",
       "1  http://v.daum.net/v/20251110100357735  \n",
       "2  http://v.daum.net/v/20251111155426418  \n",
       "3  http://v.daum.net/v/20251111151146411  \n",
       "4  http://v.daum.net/v/20251111152547093  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0_df = pd.DataFrame(result0, columns=['no', 'title','link'])\n",
    "result1_df = pd.DataFrame(result1, columns=['no', 'title','link'])\n",
    "result1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb1a9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "result0_df.to_csv(f'data/ch14_{keywords[0]}.csv', index=False, encoding='cp949')\n",
    "result1_df.to_csv(f'data/ch14_{keywords[1]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bd9de",
   "metadata": {},
   "source": [
    "### 4) User-Agent를 추가하여 크롤링\n",
    "- 자동으로 브라어저를 통해 요청하는 것 처럼 보이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2ef15a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&q=%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8\n"
     ]
    }
   ],
   "source": [
    "# 방법2 : \n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import quote\n",
    "word = quote('비트코인') # 한글을 encoding 처리\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&q='+word\n",
    "print(url)\n",
    "# headers = {'User-Agent':\n",
    "#           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "# request = Request(url, headers=headers)\n",
    "request = Request(url)\n",
    "request.add_header('User-Agent', \n",
    "                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36')\n",
    "\n",
    "response = urlopen(request)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368ff25",
   "metadata": {},
   "source": [
    "- https://www.melon.com/chart/index.htm\n",
    "    * https://wwww.melon.com/robots.txt 에서 User-Agent에 봇이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26dbfeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [406]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "url = 'https://www.melon.com/chart/index.htm'\n",
    "melonpage = requests.get(url)\n",
    "melonpage\n",
    "# soup = BeautifulSoup(melonpage.text, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c27ac937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2 : User-Agent 추가\n",
    "from urllib.request import urlopen, Request\n",
    "url = 'https://www.melon.com/chart/index.htm'\n",
    "# melonpage = urlopen(url) # 에러남\n",
    "headers = {'user-agent':\n",
    "          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "request = Request(url, headers=headers)\n",
    "melonpage = urlopen(request)\n",
    "soup = BeautifulSoup(melonpage, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d78b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위 | Blue Valentine - NMIXXNMIXX\n",
      "2위 | 타임캡슐 - 다비치다비치\n",
      "3위 | Golden - HUNTR/X, EJAE, AUDRE\n",
      "4위 | Good Goodbye - 화사 (HWASA)화사 (HWASA)\n",
      "5위 | Drowning - WOODZWOODZ\n",
      "6위 | SPAGHETTI (feat. j-hope of BTS) - LE SSERAFIM (르세라핌), \n",
      "7위 | 달리 표현할 수 없어요 - 로이킴로이킴\n",
      "8위 | 뛰어(JUMP) - BLACKPINKBLACKPINK\n",
      "9위 | Soda Pop - KPop Demon Hunters C\n",
      "10위 | 어제보다 슬픈 오늘 - 우디 (Woody)우디 (Woody)\n",
      "11위 | 시작의 아이 ❍ - 박다혜, 마크툽 (MAKTUB)박다혜\n",
      "12위 | FAMOUS - ALLDAY PROJECTALLDAY\n",
      "13위 | 모르시나요(PROD.로코베리) - 조째즈조째즈\n",
      "14위 | XOXZ - IVE (아이브)IVE (아이브)\n",
      "15위 | IRIS OUT - Kenshi YonezuKenshi \n",
      "16위 | Rich Man - aespaaespa\n",
      "17위 | 한번 더 이별 - 이창섭이창섭\n",
      "18위 | 내게 사랑이 뭐냐고 물어본다면 - 로이킴로이킴\n",
      "19위 | 너에게 닿기를 - 10CM10CM\n",
      "20위 | HOME SWEET HOME (feat. 태양, 대성) - G-DRAGONG-DRAGON\n",
      "21위 | 운명 (2025) - 먼데이 키즈, 이이경먼데이 키즈, 이\n",
      "22위 | Hollywood Action - BOYNEXTDOORBOYNEXTDO\n",
      "23위 | body - 다영 (DAYOUNG)다영 (DAYO\n",
      "24위 | toxic till the end - 로제 (ROSÉ)로제 (ROSÉ)\n",
      "25위 | Whiplash - aespaaespa\n",
      "26위 | 천상연 - 이창섭이창섭\n",
      "27위 | 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지 - AKMU (악뮤)AKMU (악뮤)\n",
      "28위 | 시작의 아이 - 마크툽 (MAKTUB)마크툽 (MAK\n",
      "29위 | 나는 반딧불 - 황가람황가람\n",
      "30위 | 청춘만화 - 이무진이무진\n",
      "31위 | HAPPY - DAY6 (데이식스)DAY6 (데이식\n",
      "32위 | like JENNIE - 제니 (JENNIE)제니 (JENNI\n",
      "33위 | 오늘만 I LOVE YOU - BOYNEXTDOORBOYNEXTDO\n",
      "34위 | 멸종위기사랑 - 이찬혁이찬혁\n",
      "35위 | APT. - 로제 (ROSÉ), Bruno Mar\n",
      "36위 | Never Ending Story - 아이유아이유\n",
      "37위 | Dirty Work - aespaaespa\n",
      "38위 | 소나기 - 이클립스 (ECLIPSE)이클립스 (\n",
      "39위 | FOCUS - Hearts2Hearts (하츠투하츠\n",
      "40위 | 한 페이지가 될 수 있게 - DAY6 (데이식스)DAY6 (데이식\n",
      "41위 | 사랑은 늘 도망가 - 임영웅임영웅\n",
      "42위 | Flower - 오반(OVAN)오반(OVAN)\n",
      "43위 | 너의 모든 순간 - 성시경성시경\n",
      "44위 | 그대만 있다면 (여름날 우리 X 너드커넥션 (Nerd Connection)) - 너드커넥션 (Nerd Connecti\n",
      "45위 | 예뻤어 - DAY6 (데이식스)DAY6 (데이식\n",
      "46위 | 모든 날, 모든 순간 (Every day, Every Moment) - 폴킴폴킴\n",
      "47위 | Welcome to the Show - DAY6 (데이식스)DAY6 (데이식\n",
      "48위 | STYLE - Hearts2Hearts (하츠투하츠\n",
      "49위 | Die With A Smile - Lady Gaga, Bruno Mar\n",
      "50위 | 주저하는 연인들을 위해 - 잔나비잔나비\n",
      "51위 | 가만히 눈을 감고 - DK(디셈버)DK(디셈버)\n",
      "52위 | TOO BAD (feat. Anderson .Paak) - G-DRAGONG-DRAGON\n",
      "53위 | REBEL HEART - IVE (아이브)IVE (아이브)\n",
      "54위 | Your Idol - KPop Demon Hunters C\n",
      "55위 | BBUU! - PLAVEPLAVE\n",
      "56위 | 사랑하게 될 거야 - 한로로한로로\n",
      "57위 | Love wins all - 아이유아이유\n",
      "58위 | 첫 만남은 계획대로 되지 않아 - TWS (투어스)TWS (투어스)\n",
      "59위 | 다정히 내 이름을 부르면 - 경서예지, 전건호경서예지, 전건호\n",
      "60위 | 청혼하지 않을 이유를 못 찾았어 - 이무진이무진\n",
      "61위 | 빌려온 고양이 (Do the Dance) - 아일릿(ILLIT)아일릿(ILLIT)\n",
      "62위 | 사랑인가 봐 - 멜로망스멜로망스\n",
      "63위 | Supernova - aespaaespa\n",
      "64위 | Dash - PLAVEPLAVE\n",
      "65위 | MY LOVE(2025) - 이예은, 아샤트리, 전건호이예은, 아\n",
      "66위 | Magnetic - 아일릿(ILLIT)아일릿(ILLIT)\n",
      "67위 | 순간을 영원처럼 - 임영웅임영웅\n",
      "68위 | 인사 - 범진범진\n",
      "69위 | 바이, 썸머 - 아이유아이유\n",
      "70위 | 헤어지자 말해요 - 박재정박재정\n",
      "71위 | 비의 랩소디 - 임재현임재현\n",
      "72위 | I AM - IVE (아이브)IVE (아이브)\n",
      "73위 | 슬픈 초대장 - 순순희(지환)순순희(지환)\n",
      "74위 | Seven (feat. Latto) - Clean Ver. - 정국정국\n",
      "75위 | 에피소드 - 이무진이무진\n",
      "76위 | WICKED - ALLDAY PROJECTALLDAY\n",
      "77위 | Hype Boy - NewJeansNewJeans\n",
      "78위 | DRIP - BABYMONSTERBABYMONST\n",
      "79위 | 고민중독 - QWERQWER\n",
      "80위 | HOT - LE SSERAFIM (르세라핌)LE\n",
      "81위 | 우리들의 블루스 - 임영웅임영웅\n",
      "82위 | PO￦ER - G-DRAGONG-DRAGON\n",
      "83위 | 내 이름 맑음 - QWERQWER\n",
      "84위 | How Sweet - NewJeansNewJeans\n",
      "85위 | JANE DOE - Kenshi Yonezu, Hikar\n",
      "86위 | HANDS UP - MEOVV (미야오)MEOVV (미야\n",
      "87위 | 다시 만날 수 있을까 - 임영웅임영웅\n",
      "88위 | 봉숭아 - PLAVEPLAVE\n",
      "89위 | 꿈의 버스 - DAY6 (데이식스)DAY6 (데이식\n",
      "90위 | OVERDRIVE - TWS (투어스)TWS (투어스)\n",
      "91위 | 들꽃이 될게요 - 임영웅임영웅\n",
      "92위 | 나는 아픈 건 딱 질색이니까 - i-dle (아이들)i-dle (아이\n",
      "93위 | 숲 - 최유리최유리\n",
      "94위 | 그댈 위한 멜로디 - 임영웅임영웅\n",
      "95위 | 숨바꼭질 (Hide and Seek) - PLAVEPLAVE\n",
      "96위 | 눈물참기 - QWERQWER\n",
      "97위 | How It’s Done - HUNTR/X, EJAE, AUDRE\n",
      "98위 | 비가 와서 - 임영웅임영웅\n",
      "99위 | 숨바꼭질 (Hide and Seek) - PLAVEPLAVE\n",
      "100위 | 천국보다 아름다운 - 임영웅임영웅\n"
     ]
    }
   ],
   "source": [
    "# 방법1 : User-Agent 추가\n",
    "url = 'https://www.melon.com/chart/index.htm'\n",
    "headers = {'user-agent':\n",
    "          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "melonpage = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(melonpage.text, # melonpage.content\n",
    "                    'html.parser')\n",
    "\n",
    "ranks = soup.select('td div.wrap.t_center > span.rank')\n",
    "titles = soup.select('div.ellipsis.rank01 > span') # title.text.strip()\n",
    "singers = soup.select('div.ellipsis.rank02') # singer.text.strip()[:20]\n",
    "# 1위 | 노래제목 - 가수명\n",
    "for rank, title, singer in zip(ranks, titles, singers):\n",
    "    print(f'{rank.text}위 | {title.text.strip()} - {singer.text.strip()[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44969df5",
   "metadata": {},
   "source": [
    "### 5) 네이버 지식인으로 검색(open API 사용X)\n",
    "- 특정 keyword를 특정페이지 수만큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "465aab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 방법1\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "keyword = '쳇지피티'\n",
    "# url = 'https://kin.naver.com/search/list.naver'\n",
    "# params = {'query' : keyword}\n",
    "# response = get(url, params=params)\n",
    "url = f'https://kin.naver.com/search/list.naver?query={keyword}'\n",
    "response = get(url)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b61db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kin.naver.com/search/list.naver?query=%EC%B3%87%EC%A7%80%ED%94%BC%ED%8B%B0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "keyword = quote('쳇지피티')\n",
    "url = f'https://kin.naver.com/search/list.naver?query={keyword}'\n",
    "print(url)\n",
    "response = urlopen(url)\n",
    "print(response.status)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4a8ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>쳇지피티 사용 확인 AI</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=5&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                                               link\n",
       "13  쳇지피티 사용 확인 AI  https://kin.naver.com/qna/detail.naver?d1id=5&..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이징 포함\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "keyword = quote('쳇지피티')\n",
    "pages = 3\n",
    "items_list = [] # 크롤링한 데이터를 담을 list(title, link)\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "    response = urlopen(url)\n",
    "    # print(response.status)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    items = soup.select('dt > a')\n",
    "    for item in items:\n",
    "        title = item.text\n",
    "        link  = item.attrs.get('href')\n",
    "        items_list.append({\n",
    "            'title': title,\n",
    "            'link' : link\n",
    "        })\n",
    "df = pd.DataFrame(items_list)\n",
    "print(df.shape)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d86e4",
   "metadata": {},
   "source": [
    "## 2.2 openAPI사용 :json 웹데이터 수집\n",
    "### \n",
    "- 네이버 개발자센터에서 애플리케이션등록(이름/검색/WEB설정http://localhost)\n",
    "- .env파일에 CLIENT_ID/CIENT_SECRET 환경변수 저장\n",
    "- 환경변수를 읽기 위해서 `pip instrall dotenv`\n",
    "- 특정 키워드롤 지식검색(데이터 수 30개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b900e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (from dotenv) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7feb7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZLPkKiVecOXweO9k8pCB\n",
      "5Oz2FXdzKh\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path = '.env')\n",
    "\n",
    "print(os.getenv('CLIENT_ID'))\n",
    "print(os.getenv('CLIENT_SECRET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "982796e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\n",
      "\t\"lastBuildDate\":\"Tue, 11 Nov 2025 16:24:37 +090\n"
     ]
    }
   ],
   "source": [
    "# 방법2\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "encText = urllib.parse.quote(\"쳇지피티\")\n",
    "url = \"https://openapi.naver.com/v1/search/kin?query=\" + encText # JSON 결과\n",
    "# request = urllib.request.Request(url)\n",
    "# request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "# request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "headers = {\n",
    "    'X-Naver-Client-Id':client_id,\n",
    "    'X-Naver-Client-Secret':client_secret\n",
    "}\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.status\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print(type(response_body.decode('utf-8')))\n",
    "    print(response_body.decode('utf-8')[:50])\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0ef7a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m items_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m---> 20\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<b>\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<b>\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     link \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m     description \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<b>\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<b>\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py:1519\u001b[0m, in \u001b[0;36mTag.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;124;03m\"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;124;03m    and throws an exception if it's not there.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json # response텍스트를 json스타일의 딕셔너리로\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "query = '쳇지피티'\n",
    "headers = {\n",
    "    'X-Naver-Client-Id':client_id,\n",
    "    'X-Naver-Client-Secret':client_secret\n",
    "}\n",
    "url = f'https://openapi.naver.com/v1/search/kin'\n",
    "params = {'query':query,'displaly':30}\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "#print(response.text[:500])\n",
    "#items = json.loads(response.text)['items']\n",
    "json.loads(response.text)['items']\n",
    "items_list = []\n",
    "for item in items:\n",
    "    title = item['title'].replace('<b>','').replace('<b>','')\n",
    "    link = item.get('link')\n",
    "    description = item.get('description').replace('<b>','').replace('<b>','')\n",
    "    items_list.append([title,link,description])\n",
    "pd.DataFrame(items_list, columns=['title','link','description']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2dab8",
   "metadata": {},
   "source": [
    "quiz) 네이버 open API를 이용해서 청바지 이미지를 100건의 데이터를 ch14_청바지.csv 출력\n",
    "제목, 링크, 썸네일, sizeheigtht, sizewidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b503ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 네이버 API 인증 정보 입력\n",
    "CLIENT_ID = 'YOUR_CLIENT_ID'\n",
    "CLIENT_SECRET = 'YOUR_CLIENT_SECRET'\n",
    "\n",
    "# 이미지 검색 API URL\n",
    "url = \"https://openapi.naver.com/v1/search/image\"\n",
    "\n",
    "load_dotenv(dotenv_path = '.env')\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "\n",
    "# 요청 헤더 설정\n",
    "headers = {\n",
    "    \"X-Naver-Client-Id\": client_id,\n",
    "    \"X-Naver-Client-Secret\": client_secret\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# 최대 100건까지 조회 (30건씩 나누어 요청)\n",
    "for start in range(1, 101, 30):\n",
    "    params = {\n",
    "        \"query\": \"청바지\",   # 검색 키워드\n",
    "        \"display\": 30,      # 한 번에 요청할 이미지 수 (최대 30)\n",
    "        \"start\": start,     # 시작 위치\n",
    "        \"sort\": \"sim\"       # 정렬 옵션 (sim: 정확도, date: 날짜)\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        items = response.json().get(\"items\", [])\n",
    "        for item in items:\n",
    "            results.append({\n",
    "                \"title\": item.get(\"title\"),\n",
    "                \"link\": item.get(\"link\"),\n",
    "                \"thumbnail\": item.get(\"thumbnail\"),\n",
    "                \"sizeheight\": item.get(\"sizeheight\"),\n",
    "                \"sizewidth\": item.get(\"sizewidth\")\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        break\n",
    "\n",
    "# 결과를 DataFrame으로 변환 후 csv 파일로 저장 (UTF-8 인코딩)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"ch14_청바지.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"청바지 이미지 100건 데이터를 ch14_청바지.csv로 저장했습니다.\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법2)'\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.parse import quote\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    encText = quote(query)\n",
    "    url = f'https://openapi.naver.com/v1/search/image?query={encText}&display=100'\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    request = Request(url, headers=headers)\n",
    "    response = urlopen(request)\n",
    "    # print(response.read().decode('utf-8'))\n",
    "    items = json.loads(response.read().decode('utf-8'))['items']\n",
    "    items_list = []\n",
    "    for item in items:\n",
    "        #print(item)\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list(\"청바지\")\n",
    "df.to_csv('data/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6cb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법1)'\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    url = 'https://openapi.naver.com/v1/search/image'\n",
    "    params = {'query':query, display:100 }\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    #items = response.json()['items']\n",
    "    items = json.loads(response.text)['items']\n",
    "    #print(items[0])\n",
    "    items_list = []\n",
    "    for item in items:\n",
    "        #print(item)\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list(\"청바지\")\n",
    "df.to_csv('data/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[0, '링크'])\n",
    "print(df.loc[0, '썸네일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b091dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(attr, idx, link, query):\n",
    "    'link의 이미지를 image/attr_idx_query.확장자로 local에 저장'\n",
    "    file_extension = link.split('.')[-1]\n",
    "    quote_index = file_extension.find('?')\n",
    "    if quote_index != -1:\n",
    "        file_extension = file_extension[:quote_index]\n",
    "    img = requests.get(link).content\n",
    "    with open(f'image/{attr}_{idx+1:02}_{query}.{file_extension}','wb') as f:\n",
    "        f.write(img)\n",
    "        \n",
    "save_image('메인',0,df.loc[0,'링크'],'청바지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d85c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list_save_image(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법1)'\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    url = 'https://openapi.naver.com/v1/search/image'\n",
    "    params = {'query':query, 'display':100 }\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    #items = response.json()['items']\n",
    "    items = json.loads(response.text)['items']\n",
    "    items_list = [] # 정보가 담길 리스트\n",
    "    for idx, item in enumerate(items):\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "        # 이미지 파일 저장\n",
    "        save_image('메인', idx, link, query)\n",
    "        save_image('썸네일', idx, thumbnail, query)\n",
    "        if (idx%20 == 0) & (idx!=0):\n",
    "            print(f'= = = {idx}% 진행중 = = =')\n",
    "    print('= = = 완료 = = =')\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list_save_image(\"청바지\")\n",
    "df.to_csv('image/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2.3 XML 웹데이터 수집\n",
    "- RSS / open API 을 통한 XML 웹데이터 수집\n",
    "### 1) 전국 날씨 RSS를 BeautifulSoup 이용한 크리\n",
    "- 구글에 기상청RSS\n",
    "url = 'http://www.kma.go.kr/repositary/xml/fct/mon/img/fct_mon1rss_108_20251106.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "items_list = []\n",
    "url = 'https://www.kma.go.kr/repositary/xml/fct/mon/img/fct_mon1rss_108_20251106.xml'\n",
    "# 방법1\n",
    "# target = requests.get(url)\n",
    "# soup = BeautifulSoup(target.text, \"xml\") # pip install lxml 필요없음\n",
    "# 방법2\n",
    "target = urlopen(url)\n",
    "soup = BeautifulSoup(target, \"xml\")\n",
    "local_tas = soup.select('local_ta')\n",
    "for local_ta in local_tas:\n",
    "    local_name = local_ta.select_one('local_ta_name').text\n",
    "    week1_normalYear = local_ta.select_one('week1_local_ta_normalYear').text\n",
    "    week1_similarRange = local_ta.select_one('week1_local_ta_similarRange').text\n",
    "    week1_minVal = local_ta.select_one('week1_local_ta_minVal').text\n",
    "    week1_similarVal = local_ta.select_one('week1_local_ta_similarVal').text\n",
    "    week1_maxVal = local_ta.select_one('week1_local_ta_maxVal').text\n",
    "    items_list.append({\n",
    "        '지역':local_name,\n",
    "        '1주평년기온':week1_normalYear,\n",
    "        '1주기온범위':week1_similarRange,\n",
    "        '1주낮을확률':week1_minVal,\n",
    "        '1주비슷할확률':week1_similarVal,\n",
    "        '1주높을확률':week1_maxVal\n",
    "    })\n",
    "pd.DataFrame(items_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d34541",
   "metadata": {},
   "source": [
    "### 2) xml응답하는 open API활용\n",
    "- data.go.kr에서\n",
    "    - 서울특별시_노선정보조회 서비시(버스ID,정류장목록과정류장ID)\n",
    "    - 서울특별시_버스위치정보조회 서비스(실시간 버스 위치 목록)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928148ea",
   "metadata": {},
   "source": [
    "# STEP 1  버스번호의 버스 id받아오기\n",
    "# 서울특별시_노선정보조회 서비스 - 3번 기능(getBusRouteList) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc62b318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# print(os.getenv('KEY'))\n",
    "# print(os.getenv('KEY1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d55c592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey=None&strSrch=162\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# urlretrieve(url, 저장경로) : url의 파일을 저장경로에 저장\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote\n",
    "# busNum = quote('구로09')\n",
    "busNum = '162'\n",
    "key = os.getenv('KEY1')\n",
    "url = f'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey={key}&strSrch={busNum}'\n",
    "print(url)\n",
    "savefilename1 = 'data/ch14_busInfo.xml'\n",
    "urlretrieve(url, savefilename1) # xml파일(url)을 savefilename으로 저장\n",
    "with open(savefilename1, encoding='utf-8') as f:\n",
    "    xml = f.read();\n",
    "soup = BeautifulSoup(xml, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "947a0054",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'busRouteId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m         busRouteId \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mselect_one(busRouteId)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m;\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusRouteId=\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mbusRouteId\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'busRouteId' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "# busNum = quote('구로09')\n",
    "busNum = '162'\n",
    "key = os.getenv('KEY1')\n",
    "url1 = f'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey={key}&strSrch={busNum}'\n",
    "response = requests.get(url1)\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "\n",
    "for item in soup.select('itemList'):\n",
    "    busRouteNm = item.select_one('busRouteNm').text\n",
    "    if busRouteNm == busnum:\n",
    "        busRouteId = item.select_one(busRouteId).text\n",
    "        break;\n",
    "print('busRouteId=',busRouteId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086d8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
